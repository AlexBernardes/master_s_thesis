{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Descrição**\n",
    "\n",
    "Este script serve como complemento à análise do One-way anova que utilizando análise de variância avaliou estatisticamente a capacidade de cada marca marcador de distinguir individualmente entre as classificações prévias dos grupos (Controle vs Diabetes Mellitus).\n",
    "\n",
    "Assim, esse script validara parcialmente o desempenho de cada um desses marcadores na classificação dos grupos e ranqueará seus desempenhos baseados nas métricas padrão de Acurácia, Precisão, Sensibilidade (Recall) e F1-score."
   ],
   "id": "2964ae99ddbe7e71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Importação de bibliotecas**",
   "id": "d449967770745790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.505269Z",
     "start_time": "2024-05-28T13:55:02.963368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Limpando ambiente\n",
    "%reset\n",
    "\n",
    "# Ignorando mensagens de aviso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Bibliotecas Relevantes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Biblioteca auxiliar para codificação das Labels\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Biblioteca para Cross Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Modelos de Treinamento\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Suporte de métricas\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ],
   "id": "6a74982a5041e0d1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Métodos para Algoritmos de Classificação**",
   "id": "b4af7d61d902485"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*SVM com Cross-validation*",
   "id": "6ccdcfe7ee92178b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.521267Z",
     "start_time": "2024-05-28T13:55:04.507267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def svm_classification_cv(X_treino, y_treino):\n",
    "    \n",
    "    # X = dataset = feature vector\n",
    "    # y = labels = target variable\n",
    "    \n",
    "    # Criação do modelo\n",
    "    svm_model = SVC(kernel='rbf') # Por que esse kernel? Pois não sabemos temos conhecimento prévio padronizado para todas os marcadores.\n",
    "    \n",
    "    # Execução do modelo, via Cross-fold x5.\n",
    "    resultados = cross_validate(svm_model, \n",
    "                                X=X_treino, \n",
    "                                y=y_treino, \n",
    "                                cv=5,\n",
    "                                scoring = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                return_train_score=True)\n",
    "    \n",
    "    # plt.plot(resultados['test_accuracy'], color=\"red\", label='Test')\n",
    "    # plt.plot(resultados['train_accuracy'], color=\"blue\", label='Train')\n",
    "    # plt.show()\n",
    "    \n",
    "    return [\n",
    "        resultados['test_accuracy'].mean(),\n",
    "        resultados['test_precision'].mean(),\n",
    "        resultados['test_recall'].mean(), \n",
    "        resultados['test_f1'].mean(),\n",
    "        resultados['train_accuracy'].mean(),\n",
    "        resultados['train_precision'].mean(),\n",
    "        resultados['train_recall'].mean(), \n",
    "        resultados['train_f1'].mean()\n",
    "    ]"
   ],
   "id": "1848f049049a5bdc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Árvore de Decisão com Cross-validation*",
   "id": "6c808509e82c681f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.536307Z",
     "start_time": "2024-05-28T13:55:04.523268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def arvore_decisao_cv(X_treino, y_treino):\n",
    "    \n",
    "    # X = dataset = feature vector\n",
    "    # y = labels = target variable\n",
    "    \n",
    "    # Criação do modelo\n",
    "    Arvore_decisao_model = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=31415) # Por que esse critério? Pois não sabemos temos conhecimento prévio padronizado para todas os marcadores.\n",
    "    \n",
    "    # Execução do modelo, via Cross-fold x5.\n",
    "    resultados = cross_validate(Arvore_decisao_model, \n",
    "                                X=X_treino, \n",
    "                                y=y_treino, \n",
    "                                cv=5,\n",
    "                                scoring = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                return_train_score=True)\n",
    "    \n",
    "    return [\n",
    "        resultados['test_accuracy'].mean(),\n",
    "        resultados['test_precision'].mean(),\n",
    "        resultados['test_recall'].mean(), \n",
    "        resultados['test_f1'].mean(),\n",
    "        resultados['train_accuracy'].mean(),\n",
    "        resultados['train_precision'].mean(),\n",
    "        resultados['train_recall'].mean(), \n",
    "        resultados['train_f1'].mean()\n",
    "    ]"
   ],
   "id": "6fe112b41a506025",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*KNN com Cross-validation*",
   "id": "df93194d654b89e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.551266Z",
     "start_time": "2024-05-28T13:55:04.538265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def knn_classification_cv(X_treino, y_treino):\n",
    "    \n",
    "    # X = dataset = feature vector\n",
    "    # y = labels = target variable\n",
    "    \n",
    "    # Criação do modelo\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "    \n",
    "    # Execução do modelo, via Cross-fold x5.\n",
    "    resultados = cross_validate(knn_model, \n",
    "                                X=X_treino, \n",
    "                                y=y_treino, \n",
    "                                cv=5,\n",
    "                                scoring = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                return_train_score=True)\n",
    "    \n",
    "    return [\n",
    "        resultados['test_accuracy'].mean(),\n",
    "        resultados['test_precision'].mean(),\n",
    "        resultados['test_recall'].mean(), \n",
    "        resultados['test_f1'].mean(),\n",
    "        resultados['train_accuracy'].mean(),\n",
    "        resultados['train_precision'].mean(),\n",
    "        resultados['train_recall'].mean(), \n",
    "        resultados['train_f1'].mean()\n",
    "    ]"
   ],
   "id": "df47e0e35747e68b",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Regressão Logística com Cross-validation",
   "id": "5edac21fa94bb19f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.567265Z",
     "start_time": "2024-05-28T13:55:04.552267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rl_classification_cv(X_treino, y_treino):\n",
    "    \n",
    "    # X = dataset = feature vector\n",
    "    # y = labels = target variable\n",
    "    \n",
    "    # Criação do modelo\n",
    "    rl_model = LogisticRegression(solver='liblinear')\n",
    "    \n",
    "    # Execução do modelo, via Cross-fold x5.\n",
    "    resultados = cross_validate(rl_model, \n",
    "                                X=X_treino, \n",
    "                                y=y_treino, \n",
    "                                cv=5,\n",
    "                                scoring = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                return_train_score=True)\n",
    "\n",
    "    return [\n",
    "        resultados['test_accuracy'].mean(),\n",
    "        resultados['test_precision'].mean(),\n",
    "        resultados['test_recall'].mean(), \n",
    "        resultados['test_f1'].mean(),\n",
    "        resultados['train_accuracy'].mean(),\n",
    "        resultados['train_precision'].mean(),\n",
    "        resultados['train_recall'].mean(), \n",
    "        resultados['train_f1'].mean()\n",
    "    ]"
   ],
   "id": "4c4fdda275df97f2",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Carregamento e preparação de dados**",
   "id": "2b96ef84a43c29c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.598832Z",
     "start_time": "2024-05-28T13:55:04.569267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Arquivos com marcadores separados por janelas e por classificação prévia (Controle vs Diabetes Mellitus)\n",
    "\n",
    "dados_sem_outliers_geral_j1 = pd.read_csv(r'C:\\Users\\AlexA\\Meu Drive\\UnB - Mestrado - Regular\\Projeto e Pesquisa\\Repositório de Dados\\Dados Pré-processados\\CDED-1.0.1-final\\Planilhas e Dados de Controle\\ML_Dataset\\Features_Without_Outliers_GERAL_Pearson_J1.csv')\n",
    "\n",
    "dados_sem_outliers_geral_j2 = pd.read_csv(r'C:\\Users\\AlexA\\Meu Drive\\UnB - Mestrado - Regular\\Projeto e Pesquisa\\Repositório de Dados\\Dados Pré-processados\\CDED-1.0.1-final\\Planilhas e Dados de Controle\\ML_Dataset\\Features_Without_Outliers_GERAL_Pearson_J2.csv')\n",
    "\n",
    "# Arquivos com marcadores separados (com_outliers) por janelas e por classificação prévia (Controle vs Diabetes Mellitus)\n",
    "\n",
    "dados_com_outliers_geral_j1 = pd.read_csv(r'C:\\Users\\AlexA\\Meu Drive\\UnB - Mestrado - Regular\\Projeto e Pesquisa\\Repositório de Dados\\Dados Pré-processados\\CDED-1.0.1-final\\Planilhas e Dados de Controle\\ML_Dataset\\Features_With_Outliers_GERAL_Spearman_J1.csv')\n",
    "\n",
    "dados_com_outliers_geral_j2 = pd.read_csv(r'C:\\Users\\AlexA\\Meu Drive\\UnB - Mestrado - Regular\\Projeto e Pesquisa\\Repositório de Dados\\Dados Pré-processados\\CDED-1.0.1-final\\Planilhas e Dados de Controle\\ML_Dataset\\Features_With_Outliers_GERAL_Spearman_J2.csv')\n",
    "\n",
    "# Caminho para salvar matrizes de difusão dos algoritmos\n",
    "\n",
    "caminho_salvamentos = r'C:\\Users\\AlexA\\Meu Drive\\UnB - Mestrado - Regular\\Projeto e Pesquisa\\Repositório de Dados\\Dados Pré-processados\\CDED-1.0.1-final\\Planilhas e Dados de Controle\\ML-1-Feature\\Individual'\n"
   ],
   "id": "acc4214d36078dfe",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Criando tabela para unificação dos Resultados**",
   "id": "16a6feb66a5e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.614852Z",
     "start_time": "2024-05-28T13:55:04.599833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Colunas do dataframe\n",
    "Colunas_metricas = ['Marcador', 'Algoritmo', 'Metodo', \n",
    "                    'Acuracia_Validacao', 'Precisao_Validacao', 'Sensibilidade_Validacao', 'F1Score_Validacao',\n",
    "                    'Acuracia_Treinamento', 'Precisao_Treinamento', 'Sensibilidade_Treinamento', 'F1Score_Treinamento',\n",
    "                    'Dados', 'DadosNaoNulos',\n",
    "                    'DM', 'CONTROLE']\n",
    "\n",
    "# Dataframes para coletas de métricas\n",
    "Metricas_KNN = pd.DataFrame(columns = Colunas_metricas)"
   ],
   "id": "692fd502e95c6ac7",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Teste de Classificação com SVM sem Cross-fold validation vs com Cross-fold validation**",
   "id": "8b9a03d7194e6c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:04.630835Z",
     "start_time": "2024-05-28T13:55:04.616833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def SVM_Execucao(dados, nome_arquivo):\n",
    "    \n",
    "    # Dataframes para coletas de métricas\n",
    "    Metricas_SVM = pd.DataFrame(columns = Colunas_metricas)\n",
    "    \n",
    "    # Separação entre dados/dataset e Labels.\n",
    "    dataset = dados.drop(['PATIENT', 'ECG', 'BP', 'ILV', 'TOTAL_AMOSTRAS_RRI', 'LABEL'], axis=1)\n",
    "    # dataset = dados[['MEDIA', 'MEDIANA']]\n",
    "    \n",
    "    dataset.drop(['LF_ILV_WELCH', 'HF_ILV_WELCH', 'LF_HF_RATIO_ILV_WELCH',\n",
    "                  'ACOPLAM_FIT_ESTIMATION', 'ACOPLAM_FIT_VALIDATION',\n",
    "                  'ACOPLAM_TIME_TO_PEAK_SAMPLE_SBP', 'ACOPLAM_TIME_TO_PEAK_SAMPLE_ILV',\n",
    "                  'ABR_FIT_ESTIMATION', 'ABR_FIT_VALIDATION', \n",
    "                  'RCC_FIT_ESTIMATION', 'RCC_FIT_VALIDATION'], axis=1, inplace=True)\n",
    "    \n",
    "    # Normalizador\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Iteração sobra colunas/marcadores\n",
    "    for marcador in dataset:\n",
    "    \n",
    "        # Remoção de nulos\n",
    "        dados_marcador = dados[[marcador, 'LABEL']].copy()\n",
    "        dados_marcador.dropna(subset=[marcador], inplace=True)\n",
    "        \n",
    "        label_marcador = dados_marcador[['LABEL']].copy()\n",
    "        dados_marcador.drop(['LABEL'], inplace=True, axis=1)\n",
    "        \n",
    "        # Normalizando os dados (Mesmo sabendo que diversos marcadores não possuem distribuição normal)\n",
    "        X_treino_CV = pd.DataFrame(scaler.fit_transform(dados_marcador), columns=[marcador])\n",
    "        \n",
    "        # Treinamento e validação dos dados com K-fold Cross-validation\n",
    "        B = np.array([marcador, 'SVM', 'CV'] + \\\n",
    "            svm_classification_cv(X_treino_CV, label_marcador) + \\\n",
    "            [dados[[marcador]].shape[0]] + \\\n",
    "            [dados_marcador.shape[0]] + \\\n",
    "            [label_marcador.astype(bool).sum(axis=0)[0]] + \\\n",
    "            [dados_marcador.shape[0] - label_marcador.astype(bool).sum(axis=0)[0]]\n",
    "        )\n",
    "        \n",
    "        Metricas_SVM.loc[len(Metricas_SVM)] = B\n",
    "        \n",
    "    Metricas_SVM.to_csv(caminho_salvamentos + '\\\\' + nome_arquivo + '.csv', index=False, na_rep='NaN')\n"
   ],
   "id": "82e1f1ed01534452",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:08.458409Z",
     "start_time": "2024-05-28T13:55:04.632834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chamada do método para execução do algoritmo\n",
    "\n",
    "SVM_Execucao(dados_sem_outliers_geral_j1.append(dados_sem_outliers_geral_j2, ignore_index=True), r'metricas_SVM_sem_outliers_geral')\n",
    "SVM_Execucao(dados_com_outliers_geral_j1.append(dados_com_outliers_geral_j2, ignore_index=True), r'metricas_SVM_com_outliers_geral')"
   ],
   "id": "e5f921c496b1f00",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Teste de Classificação com Árvore de Decisão sem Cross-fold validation**",
   "id": "ba8b7cc5c232d985"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:08.474406Z",
     "start_time": "2024-05-28T13:55:08.460406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ARVORE_DECISAO_Execucao(dados, nome_arquivo):\n",
    "    \n",
    "    # Dataframes para coletas de métricas\n",
    "    Metricas_AD = pd.DataFrame(columns = Colunas_metricas)\n",
    "    \n",
    "    # Separação entre dados/dataset e Labels.\n",
    "    dataset = dados.drop(['PATIENT', 'ECG', 'BP', 'ILV', 'TOTAL_AMOSTRAS_RRI', 'LABEL'], axis=1)\n",
    "    \n",
    "    dataset.drop(['LF_ILV_WELCH', 'HF_ILV_WELCH', 'LF_HF_RATIO_ILV_WELCH',\n",
    "                  'ACOPLAM_FIT_ESTIMATION', 'ACOPLAM_FIT_VALIDATION',\n",
    "                  'ACOPLAM_TIME_TO_PEAK_SAMPLE_SBP', 'ACOPLAM_TIME_TO_PEAK_SAMPLE_ILV',\n",
    "                  'ABR_FIT_ESTIMATION', 'ABR_FIT_VALIDATION', \n",
    "                  'RCC_FIT_ESTIMATION', 'RCC_FIT_VALIDATION'], axis=1, inplace=True)\n",
    "    \n",
    "    # Normalizador\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Iteração sobra colunas/marcadores\n",
    "    for marcador in dataset:\n",
    "    \n",
    "        # Remoção de não nulos\n",
    "        dados_marcador = dados[[marcador, 'LABEL']].copy()\n",
    "        dados_marcador.dropna(inplace=True, axis=0)\n",
    "        \n",
    "        label_marcador = dados_marcador[['LABEL']].copy()\n",
    "        dados_marcador.drop(['LABEL'], inplace=True, axis=1)\n",
    "        \n",
    "        # Normalizando os dados (Mesmo sabendo que diversos marcadores não possuem distribuição normal)\n",
    "        X_treino_CV = pd.DataFrame(scaler.fit_transform(dados_marcador), columns=[marcador])\n",
    "\n",
    "        # Treinamento e validação dos dados com K-fold Cross-validation\n",
    "        B = np.array([marcador, 'ARVORE_DECISAO', 'CV'] + \\\n",
    "            arvore_decisao_cv(X_treino_CV, label_marcador) + \\\n",
    "            [dados[[marcador]].shape[0]] + \\\n",
    "            [dados_marcador.shape[0]] + \\\n",
    "            [label_marcador.astype(bool).sum(axis=0)[0]] + \\\n",
    "            [dados_marcador.shape[0] - label_marcador.astype(bool).sum(axis=0)[0]]\n",
    "        )\n",
    "\n",
    "        Metricas_AD.loc[len(Metricas_AD)] = B\n",
    "\n",
    "    Metricas_AD.to_csv(caminho_salvamentos + '\\\\' + nome_arquivo + '.csv', index=False, na_rep='NaN')"
   ],
   "id": "5d48cbce1906e762",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:11.924279Z",
     "start_time": "2024-05-28T13:55:08.475406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ARVORE_DECISAO_Execucao(dados_sem_outliers_geral_j1.append(dados_sem_outliers_geral_j2, ignore_index=True), r'metricas_AD_sem_outliers_geral')\n",
    "ARVORE_DECISAO_Execucao(dados_com_outliers_geral_j1.append(dados_com_outliers_geral_j2, ignore_index=True), r'metricas_AD_com_outliers_geral')"
   ],
   "id": "81e422770b85f790",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Teste de Classificação com K-nearest Neighbour sem Cross-fold validation**",
   "id": "b8364a81e7b4ddb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:11.940199Z",
     "start_time": "2024-05-28T13:55:11.926196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def KNN_Execucao(dados, nome_arquivo):\n",
    "    \n",
    "    # Dataframes para coletas de métricas\n",
    "    Metricas_KNN = pd.DataFrame(columns = Colunas_metricas)\n",
    "    \n",
    "    # Separação entre dados/dataset e Labels.\n",
    "    dataset = dados.drop(['PATIENT', 'ECG', 'BP', 'ILV', 'TOTAL_AMOSTRAS_RRI', 'LABEL'], axis=1)\n",
    "    \n",
    "    dataset.drop(['LF_ILV_WELCH', 'HF_ILV_WELCH', 'LF_HF_RATIO_ILV_WELCH',\n",
    "                  'ACOPLAM_FIT_ESTIMATION', 'ACOPLAM_FIT_VALIDATION',\n",
    "                  'ACOPLAM_TIME_TO_PEAK_SAMPLE_SBP', 'ACOPLAM_TIME_TO_PEAK_SAMPLE_ILV',\n",
    "                  'ABR_FIT_ESTIMATION', 'ABR_FIT_VALIDATION', \n",
    "                  'RCC_FIT_ESTIMATION', 'RCC_FIT_VALIDATION'], axis=1, inplace=True)\n",
    "    \n",
    "    # Normalizador\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Iteração sobra colunas/marcadores\n",
    "    for marcador in dataset:\n",
    "    \n",
    "        # Remoção de não nulos\n",
    "        dados_marcador = dados[[marcador, 'LABEL']].copy()\n",
    "        dados_marcador.dropna(inplace=True, axis=0)\n",
    "\n",
    "        label_marcador = dados_marcador[['LABEL']].copy()\n",
    "        dados_marcador.drop(['LABEL'], inplace=True, axis=1)\n",
    "        \n",
    "        # Normalizando os dados (Mesmo sabendo que diversos marcadores não possuem distribuição normal)\n",
    "        X_treino_CV = pd.DataFrame(scaler.fit_transform(dados_marcador), columns=[marcador])\n",
    "\n",
    "        # Treinamento e validação dos dados com K-fold Cross-validation\n",
    "        B = np.array([marcador, 'KNN', 'CV'] + \\\n",
    "            knn_classification_cv(X_treino_CV, label_marcador) + \\\n",
    "            [dados[[marcador]].shape[0]] + \\\n",
    "            [dados_marcador.shape[0]] + \\\n",
    "            [label_marcador.astype(bool).sum(axis=0)[0]] + \\\n",
    "            [dados_marcador.shape[0] - label_marcador.astype(bool).sum(axis=0)[0]]\n",
    "        )\n",
    "\n",
    "        Metricas_KNN.loc[len(Metricas_KNN)] = B\n",
    "\n",
    "    Metricas_KNN.to_csv(caminho_salvamentos + '\\\\' + nome_arquivo + '.csv', index=False, na_rep='NaN')"
   ],
   "id": "47265a6bb209c145",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:16.568148Z",
     "start_time": "2024-05-28T13:55:11.942198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "KNN_Execucao(dados_sem_outliers_geral_j1.append(dados_sem_outliers_geral_j2, ignore_index=True), r'metricas_KNN_sem_outliers_geral')\n",
    "KNN_Execucao(dados_com_outliers_geral_j1.append(dados_com_outliers_geral_j2, ignore_index=True), r'metricas_KNN_com_outliers_geral')"
   ],
   "id": "5d75902e2fd31537",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Teste de classificação com Regressão Logística**",
   "id": "477af237b53f66c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:16.584156Z",
     "start_time": "2024-05-28T13:55:16.569178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def RL_Execucao(dados, nome_arquivo):\n",
    "    \n",
    "    # Dataframes para coletas de métricas\n",
    "    Metricas_RL = pd.DataFrame(columns = Colunas_metricas)\n",
    "    \n",
    "    # Separação entre dados/dataset e Labels.\n",
    "    dataset = dados.drop(['PATIENT', 'ECG', 'BP', 'ILV', 'TOTAL_AMOSTRAS_RRI', 'LABEL'], axis=1)\n",
    "    \n",
    "    dataset.drop(['LF_ILV_WELCH', 'HF_ILV_WELCH', 'LF_HF_RATIO_ILV_WELCH',\n",
    "                  'ACOPLAM_FIT_ESTIMATION', 'ACOPLAM_FIT_VALIDATION',\n",
    "                  'ACOPLAM_TIME_TO_PEAK_SAMPLE_SBP', 'ACOPLAM_TIME_TO_PEAK_SAMPLE_ILV',\n",
    "                  'ABR_FIT_ESTIMATION', 'ABR_FIT_VALIDATION', \n",
    "                  'RCC_FIT_ESTIMATION', 'RCC_FIT_VALIDATION'], axis=1, inplace=True)\n",
    "    \n",
    "    # Normalizador\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Iteração sobra colunas/marcadores\n",
    "    for marcador in dataset:\n",
    "    \n",
    "        # Remoção de não nulos\n",
    "        dados_marcador = dados[[marcador, 'LABEL']].copy()\n",
    "        dados_marcador.dropna(inplace=True, axis=0)\n",
    "\n",
    "        label_marcador = dados_marcador[['LABEL']].copy()\n",
    "        dados_marcador.drop(['LABEL'], inplace=True, axis=1)\n",
    "        \n",
    "        # Normalizando os dados (Mesmo sabendo que diversos marcadores não possuem distribuição normal)\n",
    "        X_treino_CV = pd.DataFrame(scaler.fit_transform(dados_marcador), columns=[marcador])\n",
    "\n",
    "        # Treinamento e validação dos dados com K-fold Cross-validation\n",
    "        B = np.array([marcador, 'RL', 'CV'] + \\\n",
    "            rl_classification_cv(X_treino_CV, label_marcador) + \\\n",
    "            [dados[[marcador]].shape[0]] + \\\n",
    "            [dados_marcador.shape[0]] + \\\n",
    "            [label_marcador.astype(bool).sum(axis=0)[0]] + \\\n",
    "            [dados_marcador.shape[0] - label_marcador.astype(bool).sum(axis=0)[0]]\n",
    "        )\n",
    "\n",
    "        Metricas_RL.loc[len(Metricas_RL)] = B\n",
    "\n",
    "    Metricas_RL.to_csv(caminho_salvamentos + '\\\\' + nome_arquivo + '.csv', index=False, na_rep='NaN')"
   ],
   "id": "aca96d6673e071fc",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:55:19.651781Z",
     "start_time": "2024-05-28T13:55:16.585157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RL_Execucao(dados_sem_outliers_geral_j1.append(dados_sem_outliers_geral_j2, ignore_index=True), r'metricas_RL_sem_outliers_geral')\n",
    "RL_Execucao(dados_com_outliers_geral_j1.append(dados_com_outliers_geral_j2, ignore_index=True), r'metricas_RL_com_outliers_geral')"
   ],
   "id": "2e067bd43fa2cbb9",
   "outputs": [],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
